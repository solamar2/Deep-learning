Assignment 3 involves constructing a recurrent neural network (RNN) and applying it to a real-world dataset. The assignment not only provides practical experience in building the network but also introduces the challenge of integrating multiple sources of information into a single, cohesive framework.

Two models were tested, both with the same architecture but differing in MIDI feature inputs. Mode 1 utilized a 23-dimensional vector representing general musical characteristics, while Mode 2 employed a 145-dimensional vector focusing on specific musical instruments. Mode 1 achieved a lower loss, with both models showing effective learning and minimal overfitting, as indicated by the parallel decrease in training and validation losses. However, both models struggled on the test set, likely due to incomplete loss convergence and issues like word repetition in generated songs. Experiments with time-sequential features and varying initial words revealed that the starting context significantly influenced the thematic development of the lyrics.
